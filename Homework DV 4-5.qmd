---
title: "Homework DV 4-5"
author: "Logan Agin"
format: html
editor: visual
embed-resources: true
---

# \# Chapter 4 - Data Visualization

Here, we are going to practice and reinforce some of the key ideas from chapter 4.

## \## Question 1 

We are going to work with a dataset of TV Ratings taken from IMDB. Let's read it in and see what we have.

```{r}
library(tidyverse)
library(patchwork)

tv_ratings <- read_csv("https://raw.githubusercontent.com/vaiseys/dav-course/main/Data/tv_ratings.csv")

glimpse(tv_ratings)
```

library(tidyverse)

\# Read in the data

tv_ratings \<- read_csv("https://raw.githubusercontent.com/vaiseys/dav-course/main/Data/tv_ratings.csv")

\# Glimpse the data

glimpse(tv_ratings)

\`\`\`

\`\`\`

\## Rows: 2,266

\## Columns: 7

\## \$ titleId \<chr\> "tt2879552", "tt3148266", "tt3148266", "tt3148266", "tt31...

\## \$ seasonNumber \<dbl\> 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 1, 1, 1, ...

\## \$ title \<chr\> "11.22.63", "12 Monkeys", "12 Monkeys", "12 Monkeys", "12...

\## \$ date \<date\> 2016-03-10, 2015-02-27, 2016-05-30, 2017-05-19, 2018-06-...

\## \$ av_rating \<dbl\> 8.4890, 8.3407, 8.8196, 9.0369, 9.1363, 8.4370, 7.5089, 8...

\## \$ share \<dbl\> 0.51, 0.46, 0.25, 0.19, 0.38, 2.38, 2.19, 6.67, 7.13, 5.8...

\## \$ genres \<chr\> "Drama,Mystery,Sci-Fi", "Adventure,Drama,Mystery", "Adven...

\`\`\`

We notice that each row is a season-title pair. Then we get the average rating for that season of that show, and the corresponding genre.

The first thing that we are going to look at is how rating develops across seasons, for different genres. To do this, we need shows that have lasted a while. The following bit of code counts how many seasons each show has and then keeps those shows that have had 5 seasons or more.

```{r}
tv_long <- tv_ratings %>% 

  group_by(title) %>% 

  summarise(num_seasons = n()) %>% 

  ungroup() %>% 

  left_join(tv_ratings, by = "title") 

tv_long <- tv_long %>% 

  filter(num_seasons >= 5)
```

tv_long \<- tv_ratings %\>%

group_by(title) %\>%

summarise(num_seasons = n()) %\>%

ungroup() %\>%

left_join(tv_ratings, by = "title")

tv_long \<- tv_long %\>%

filter(num_seasons \>= 5)

\`\`\`

Use \`tv_long\` to make a line plot to trace how average ratings evolve across seasons. Remember to use the group aesthetic so that each line represents one show.

```{r}
tv_long2 <- tv_long %>% 
  group_by(title)
p1 <- ggplot(tv_long, 
             aes(x = date, 
                 y = av_rating,
                 group = title)) +
  geom_line() 
p1
```

It should look fairly messy. Can you draw any conclusions from it?

I cannot come to any concise conclusions.

## \## Question 2

Facet the plot above by \`genres\` so that we can see patterns more clearly.

```{r}
ggplot(tv_long, 
             aes(x = date, 
                 y = av_rating,
                 group = title)) +
  geom_point(alpha = .2) + 
  facet_wrap(~ genres) + 
  theme_minimal()

```

What shows tend to last longer? Do ratings change much across seasons? Can you identify that show on \`Drama, Family, Fantasy\` whose ratings just plummeted?

It looks like Dramas last the longest, but Drama is in pretty much every show. It also looks like Action and Crime last a while. Yes, ratings do change over seasons and the change can vary. From the graph I cannot, but from the data set you can see that 'Are You Afraid of the Dark?' is the show whose ratings dropped.

## \## Question 3 

Let's look at the \`genres\` that show up in the best rated shows.

First, filter the original data set - \`tv_ratings\` - so that it only includes rows where the average rating is higher or equal than 9.

Make a barplot where the x-axis is \`genre\`.

The result should be hard to read - the names of the genres are quite long. Add \`coord_flip()\` to the end of your ggplot call and watch the results get clearer. Tell me what \`coord_flip()\` does.

```{r}
tv_long_filter<- tv_long %>% 
  filter(av_rating >= 9)

ggplot(tv_long_filter, 
       aes(x = genres)) + 
  geom_bar() + 
  coord_flip()+
  theme_minimal()
```

What is the genre with the most top-rated shows?

`coord_flip` switches the x and the y axis, flipping the bar graph on the side. This allows us to read the data better. 'Action, Crime, Drama' and 'Action, Adventure, Drama' both have a value of 7, the highest value.

## \## Question 4 

As a comedy fan, I am quite distraught by the results. I want to compare the range of average ratings that comedies and dramas get. Surely there are many bad comedies but the best comedies should rival the best dramas. Right?

For this, we need to do a bit of wrangling that I am going to walk you through.

First, because the \`genres\` names are so convoluted, I am going to classify everything that includes the word "Comedy" as a comedy.

```{r}
comedies_dramas <- tv_ratings %>% 

  mutate(is_comedy = if_else(str_detect(genres, "Comedy"), 

                             1, 

                             0)) %>% # If it contains the word comedy then 1, else 0

  filter(is_comedy == 1 | genres == "Drama") %>% # Keep comedies and dramas

  mutate(genres = if_else(genres == "Drama", # Make it so that we only have those two genres

                          "Drama", 

                          "Comedy"))

glimpse(comedies_dramas)
```

comedies_dramas \<- tv_ratings %\>%

mutate(is_comedy = if_else(str_detect(genres, "Comedy"),

1,

0)) %\>% \# If it contains the word comedy then 1, else 0

filter(is_comedy == 1 \| genres == "Drama") %\>% \# Keep comedies and dramas

mutate(genres = if_else(genres == "Drama", \# Make it so that we only have those two genres

"Drama",

"Comedy"))

glimpse(comedies_dramas)

\`\`\`

\`\`\`

\## Rows: 684

\## Columns: 8

\## \$ titleId \<chr\> "tt0312081", "tt0312081", "tt0312081", "tt1225901", "tt12...

\## \$ seasonNumber \<dbl\> 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 1, 25, 1, 1, 2, 3, 4, 5, 1,...

\## \$ title \<chr\> "8 Simple Rules", "8 Simple Rules", "8 Simple Rules", "90...

\## \$ date \<date\> 2002-09-17, 2003-11-04, 2004-11-12, 2009-01-03, 2009-11-...

\## \$ av_rating \<dbl\> 7.5000, 8.6000, 8.4043, 7.1735, 7.4686, 7.6858, 6.8344, 7...

\## \$ share \<dbl\> 0.03, 0.10, 0.06, 0.40, 0.14, 0.10, 0.04, 0.01, 0.48, 0.4...

\## \$ genres \<chr\> "Comedy", "Comedy", "Comedy", "Comedy", "Comedy", "Comedy...

\## \$ is_comedy \<dbl\> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...

\`\`\`

Now, you should have a dataset with shows that are categorized as either drama or comedies.

Plot a density plot that shows the distribution of average ratings for both comedies and dramas.

```{r}
ggplot(comedies_dramas,
       aes(x = av_rating, group = genres, color = genres))+ 
  geom_density()+ 
  labs(x = "Average Rating", title = "Density Plot Drama vs. Comedy") + 
  theme_minimal() 

genre_avg_ratings <- comedies_dramas %>%
  group_by(genres) %>%
  summarize(avg_rating = mean(av_rating))
genre_avg_ratings
```

How does my prediction above hold? Are dramas rated higher?

Your predictions are correct. The best comedies are averaged at a higher rate than the best dramas.

|        |          |
|:-------|---------:|
| Comedy | 8.040437 |
| Drama  | 8.001338 |

## \## Question 5

Let's experiment with different ways of visualizing this. First, do the same plot using histograms.

What additional information does this give you?

\> Hint: look at the size of the bars. I probably categorized way too many shows as "comedies". I had to stack the deck.

```{r}
ggplot(comedies_dramas,
       aes(x = av_rating, fill = genres)) + 
         geom_histogram() + 
         facet_wrap(~genres) + 
         theme_minimal()
```

This information tells us that there are way more comedies at a higher average rating compared to dramas.

Now, use \`geom_freqpoly()\`. What do you notice? Of the three plots, which one do you think it's more informative?

```{r}
ggplot(comedies_dramas,
       aes(x = av_rating, group = genres, color = genres)) + 
         geom_freqpoly() + 
         theme_minimal()
```

I notice that comedies have a way higher frequency than dramas. This tells us that there are more highly rated comedies than dramas. Of the three, I think that `geom_freqpoly()` is the most informative.

## \## Question 6 

Let's now explore whether the actual quality of the show corresponded to how many people were paying attention. The column \`share\` indicates the share of viewership that that show and season acquired. We are going to examine the relationship between average rating and share of viewership.

Take our \`comedies_dramas\` dataset and make a plot where average rating is on the x-axis and share on the y-axis. Use \`geom_bin_2d()\` to make the plot.

```{r}
ggplot(comedies_dramas, 
       aes(x = av_rating, 
           y = share,
          fill = genres))+ 
  geom_bin_2d() + 
  theme_minimal()
```

What do you see? What additional information does this give you in comparison to a scatter plot?

Most shows that are rated around 8 has the most density at 0 share. This tells us that not a lot of people watched these 8 rated shows. `geom_bin_2d()` tells us where most of the points on the data set are plotted. From this we can see that most 8 rated shows have about a 0 share to them way easier than we could in a scatter plot.

Now add \`genres\` to the fill aesthetic. What patterns do you see? Can you identify that big outlier that apparently captured the nation?

I can now see that comedies are watched a higher rate than dramas. Dekalog is the drama with a very high share and about 8 rating.

# \# Chapter 5 - Data Visualization

Here, we are going to practice some of the skills emphasized in Chapter 5. At first, it may seem that a lot of the skills are similar to those we learned in Modern Dive. I have two responses to that. First, you are right; repetition is important. That's how we learn things. Second, this chapter presents some incredibly handy tricks that as a Data Analyst you will use all the time. In these exercises, we are going to be using data from the WNCAA tournament.

As always, let's begin by reading in the data.

```{r}
library(tidyverse)

# Read in the data 

wncaa <- read_csv("https://raw.githubusercontent.com/vaiseys/dav-course/main/Data/wncaa.csv")

# Glimpse the data 

glimpse(wncaa)
```

We have data for all teams that have made it to the WNCAA tournament. We have a wealth of information from \`reg_percent\`, the percentage of wins in the regular season, to the place they ended in a given tournament (\`tourney_finish\`).

## \## Question 1

Let's practice some of the summarizing skills that Healy introduces. We are going to examine the percentage of tournaments that schools have won.

First, \`filter\` the dataset for observations where \`tourney_finish\` equals \`Champ\`.

```{r}
wncaa_champ <- wncaa %>% 
  filter(tourney_finish == "Champ")
```

Now, use \`group_by\` and \`summarize\` to calculate the percentage of tournaments each team has.

```{r}
percent_wncaa_champ <- wncaa_champ %>% 
  group_by(school) %>% 
  summarise(percentage = n()/nrow(wncaa_champ)*100)
```

\> Hint: look at the first code chunk of the chapter.

Plot a bar plot that shows these percentages by school.

```{r}
g1 <- ggplot(percent_wncaa_champ, 
       aes(x = percentage, fill = school)) + 
  geom_bar()+
  #facet_wrap(~school)+
  theme_minimal()

g2 <- ggplot(percent_wncaa_champ,
             aes(x = percentage))+ 
  geom_bar() + 
  theme_minimal()

g1+g2
```

What patterns do you see? Who are the two teams that have won the most?

I see that most of the teams have a very low percentage expect Tennessee and UCONN.

## \## Question 2 

Let's now look at how the top teams have been seeded as they enter into the tournament. Let's begin by creating a dataset that includes just the "top teams". How are we going to do this? Well, let's take the teams that show up in your bar plot above. We are going to work with the dataset that only includes teams that have ever won the tournament. I'll show you how to do it.

The dataset I created for the plot above is called \`champs\`. Let's get the names of the champions:

```{r}
champ_names <- unique(wncaa_champ$school)
champ_names
```

Now, we filter our original name so that only these schools are included.

```{r}
winners <- wncaa %>% 

  filter(school %in% champ_names)
```

Now, make a plot that shows boxplots for the distribution of \`seeds\` for each school. Make sure you use \`coord_flip()\` so that the school names are legible.

```{r}
ggplot(winners,
       aes(x = seed,
           y = reorder(school,seed)) + 
  geom_boxplot()+ 
  theme_minimal()
```

These days, it's good practice to add all the data points in addition to the boxplot. You can use \`geom_jitter()\` to do this. Don't forget to use \`outlier.shape = NA\` in the boxplot so you don't plot the outliers twice.

```{r}
ggplot(winners,
       aes(x = seed,
           y = reorder(school,seed)))+ 
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(width = .2, alpha = .5) + 
  labs(x= "Seed", y = "School", title = "Average Rank Per Team") + 
  theme_minimal()
```

We will also want to organize the plots so that they convey information more clearly. Use the \`reorder()\` trick to show the distributions in a an order that is easier to understand. You will need to calculate some school-specific statistics to use for the reordering. (You might find \`group_by()\` and \`mutate()\` valuable here, although there are several ways to do this.)

Describe the results? Any surprises?

Tennessee and UCONN are ranked the highest out of the data most of the time. After those two, there is a lot more variation in seeds between schools. Maryland on average is ranked 3rd but has only been ranked 3rd a couple of times telling us that `geom_jitter` allows us to look at the information more clearly.

Try to make the same plot using \`geom_violin()\` instead of \`geom_boxplot()\`. Which visualization do you think is more informative? There's no right answer here but provide some reasoning to justify your choice.

```{r}
ggplot(winners,
       aes(x = seed,
           y = reorder(school,seed)))+ 
  geom_violin(outlier.shape = NA) +
  geom_jitter(width = .2, alpha = .5) + 
  labs(x= "Seed", y = "School", title = "Average Rank Per Team") + 
  theme_minimal()
```

I like violin better because it shows us where most of the data points are falling. UCONN and Tennessee shows up very well but as the data gets more varied it is a little harder to read for someone on the outside.

## \## Question 3 

Try making the plot above but using \`geom_point\` only. Why does it not work very well?

```{r}
ggplot(winners,
       aes(x = seed,
           y = reorder(school,seed)))+ 
  geom_point(outlier.shape = NA) +
  labs(x= "Seed", y = "School", title = "Average Rank Per Team") + 
  theme_minimal()
```

It does not work very well because it does not give us the amount of times that the data point is being hit. Just that the fact that at one point they were ranked at that certain rank. For example, Texas Tech was ranked 1 only once but it looks the same as UCONN's.

## \## Question 4 

Okay, now let's try the \`summarize_if()\` verb. Let's make a new data frame by taking the \`winners\` dataset, grouping by school, and take the \`mean()\` and \`sd()\` of the columns \*\*if\*\* they are numeric. HINT: you can also use the newer \`across()\` syntax for this if you prefer. It looks like this:

```{r}
winners_mean_sd <- winners |> 

  group_by(school) |> 

  summarize(across(where(is.numeric),

                   list(mean = mean,

                        sd = sd)))
```

Let's explore the average win percentage of these schools across the seasons. In your new dataset, this column should be called \`reg_percent_mean\`. Make a dot plot, where this column is in the y-axis and school is the x-axis. Again, use our tricks, \`coord_flip\` and \`reorder\` to make the plot legible. (Or you can specify the proper axes from the start if you like. Sometimes this is easier, but not always!)

```{r}
ggplot(winners_mean_sd, 
       aes(x = reg_percent_mean,
           y = reorder(school,reg_percent_mean))) +
  geom_point()+ 
  theme_minimal()
    
```

Describe the results. Which tournament winner had the lowest regular season win percentage?

The results are surprising. I would thin Tennessee would have a higher reg_percent_mean because of their consent rank 1. This is not the case. Texan A&M has the lowest.

Now, let's try to take into account the standard deviation. Use the \`geom_pointrange\` to show the intervals of one standard deviation below and above the mean (just like Figure 5.15 in the online version of socviz.co).

```{r}
ggplot(winners_mean_sd, aes(x = reorder(school, reg_percent_mean), y = reg_percent_mean)) +
  geom_point() +
  geom_pointrange(aes
                  (ymin = reg_percent_mean - reg_percent_sd, 
                   ymax = reg_percent_mean + reg_percent_sd)) +
  coord_flip() +
  labs(x = "School", y = "Average Win Percentage") +
  theme_minimal()
```

What is the school with the narrowest interval? What does this mean?

Texas A%M has the narrowest interval. This means that their average win percentage has the least variation.

Can you make the same plot using \`geom_linerange\` ? Do you think this is a good or bad idea? Why? There is no right answer; just give your reasoning.

You can. In this case `geom_pointrange()` is better because it shows the win percentage distribution directly and focuses more on the mean.
